{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TCC-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPMH480I4nGPI4Iu7AvAPwK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victoralcantara75/erythrocytes-classification/blob/develop/TCC_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeBHdOx21G22"
      },
      "source": [
        "#math\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import skimage\n",
        "import sklearn.model_selection\n",
        "\n",
        "#ts and keras\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#dimensionality\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#classificators\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import naive_bayes\n",
        "\n",
        "#visualization\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#utils\n",
        "import os\n",
        "import imageio\n",
        "from datetime import datetime"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POrVE1u93Zns",
        "outputId": "be44ca3c-d1d2-4f93-b886-03f0eae6d6da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#dataset\n",
        "!git clone https://github.com/victoralcantara75/train-test-erythrocytes.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'train-test-erythrocytes'...\n",
            "remote: Enumerating objects: 769, done.\u001b[K\n",
            "remote: Counting objects: 100% (769/769), done.\u001b[K\n",
            "remote: Compressing objects: 100% (565/565), done.\u001b[K\n",
            "remote: Total 769 (delta 203), reused 766 (delta 203), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (769/769), 738.18 KiB | 21.09 MiB/s, done.\n",
            "Resolving deltas: 100% (203/203), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCt_jyqMaaCR"
      },
      "source": [
        "classes = [\"circular\", \"falciforme\", \"outras\"]\n",
        "classificators = [\"svm\", \"bayes\"]\n",
        "batch = 16\n",
        "epochs = 30\n",
        "opt = 'adam'\n",
        "lr = 0.001"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36RMZfSnUgR_"
      },
      "source": [
        "def loadDir(k, round):\n",
        "  train_dir = './train-test-erythrocytes/dataset/'+str(k)+'-fold/round_'+str(round)+'/train'\n",
        "  test_dir = './train-test-erythrocytes/dataset/'+str(k)+'-fold/round_'+str(round)+'/test'\n",
        "  return train_dir, test_dir"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtCpCaf_LVl_"
      },
      "source": [
        "def createSaveFile(net):\n",
        "  dir = str(net)+\"/\"\n",
        "  if not(os.path.isdir(dir)):\n",
        "    os.mkdir(dir)\n",
        "\n",
        "  today = datetime.today()\n",
        "  path = dir + str(today) + \".txt\" \n",
        "\n",
        "  saveFile = open(path, 'a')\n",
        "  return saveFile"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJQmLKssYaUW"
      },
      "source": [
        "def createModel(net):\n",
        "\n",
        "  if net == \"resnet\":\n",
        "    base_model = ResNet50(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
        "  if net == \"eff\":\n",
        "    base_model = EfficientNetB7(weights='imagenet', include_top=True)\n",
        "  vector = base_model.get_layer(\"avg_pool\").output\n",
        "  model = tf.keras.Model(base_model.input, vector)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zqo-LLmRyERH"
      },
      "source": [
        "def toArray(X_list_train, Y_list_train, X_list_test, Y_list_test):\n",
        "  train_imgs = np.asarray(X_list_train, dtype=np.float32)\n",
        "  train_labels = np.asarray(Y_list_train, dtype=np.float32)\n",
        "\n",
        "  test_imgs = np.asarray(X_list_test, dtype=np.float32)\n",
        "  test_labels = np.asarray(Y_list_test, dtype=np.float32)\n",
        "\n",
        "  return train_imgs, train_labels, test_imgs, test_labels\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cne2pnAZpSl_"
      },
      "source": [
        "def extract_features_test(path, model):\n",
        "  print('extracting features')\n",
        "  x_list = []\n",
        "  y_list = []\n",
        "\n",
        "  for label in range(3):    \n",
        "    folder_path = os.path.join(path, classes[label])\n",
        "    for file in os.listdir(folder_path):    \n",
        "        file_path = os.path.join(folder_path, file)\n",
        "        \n",
        "        if not(file.endswith(\".jpg\")):\n",
        "            continue\n",
        "        \n",
        "        # load image\n",
        "        img = image.load_img(file_path, target_size=(224,224))\n",
        "        # convert image to numpy array\n",
        "        img_arr = image.img_to_array(img)\n",
        "        # add 1 more dimension\n",
        "        img_arr_b = np.expand_dims(img_arr, axis=0)\n",
        "        # preprocess image\n",
        "        input_img = preprocess_input(img_arr_b)\n",
        "        # extract feature\n",
        "        features = model.predict(input_img)\n",
        "\n",
        "        x_list.append(features.ravel())\n",
        "        y_list.append(label)\n",
        "\n",
        "  return x_list, y_list"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYEYax2fKtYK"
      },
      "source": [
        "def extract_features_train(path, model):\n",
        "  print('extracting features')\n",
        "  x_list = []\n",
        "  y_list = []\n",
        "\n",
        "  for label in range(3):    \n",
        "    folder_path = os.path.join(path, classes[label])\n",
        "    for file in os.listdir(folder_path):    \n",
        "        file_path = os.path.join(folder_path, file)\n",
        "        \n",
        "        if not(file.endswith(\".jpg\")):\n",
        "            continue\n",
        "        \n",
        "        # load image\n",
        "        img = image.load_img(file_path, target_size=(224,224))\n",
        "        # convert image to numpy array\n",
        "        img_arr = image.img_to_array(img)\n",
        "        # add 1 more dimension\n",
        "        img_arr_b = np.expand_dims(img_arr, axis=0)\n",
        "        # preprocess image\n",
        "        input_img = preprocess_input(img_arr_b)\n",
        "        #data augmentation\n",
        "        da = []\n",
        "        img_vertical_flip = np.flipud(input_img)\n",
        "        img_horizontal_flip = np.fliplr(input_img)\n",
        "        da.append(input_img)\n",
        "        da.append(img_vertical_flip)\n",
        "        da.append(img_horizontal_flip)\n",
        "        # extract feature\n",
        "        for data in da:\n",
        "          features = model.predict(data)\n",
        "          x_list.append(features.ravel())\n",
        "          y_list.append(label)\n",
        "\n",
        "  return x_list, y_list"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z19EBgh3yozp"
      },
      "source": [
        "def reduct_features(imgs):\n",
        "  print('reducting features')\n",
        "  pca = PCA(n_components=3)\n",
        "  pca.fit(imgs)\n",
        "  reduc_features = pca.transform(imgs)\n",
        "  return reduc_features\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc6_J0QY61XU"
      },
      "source": [
        "def classificate(name, clf, accs, train_features, train_labels, test_features, test_labels, saveFile):\n",
        "  clf.fit(train_features, train_labels)\n",
        "  preds = clf.predict(test_features)\n",
        "\n",
        "  report = classification_report(test_labels, preds, target_names=classes, output_dict=True)\n",
        "  accs.append(report['accuracy'])\n",
        "  print(\"Accuracy: \", report['accuracy'])\n",
        "  saveFile.write(name + '\\n')\n",
        "  saveFile.write(classification_report(test_labels, preds, target_names=classes))\n",
        "  return accs"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZmZH53BOe45"
      },
      "source": [
        "def svm_grid_search(C, kernel, train_X, train_Y):\n",
        "    accuracy_score_list = []\n",
        "    \n",
        "    for c in C:\n",
        "        # Model training\n",
        "        svmClassifier = SVC(C = c, kernel = kernel)\n",
        "        svmClassifier.fit(train_X, train_Y.ravel())\n",
        "        # Prediction on test set\n",
        "        pred_y = svmClassifier.predict(train_X)\n",
        "        # Accuracy\n",
        "        accuracy = accuracy_score(train_Y, pred_y)\n",
        "        accuracy_score_list.append(accuracy)\n",
        "        print('Regularization parameters: ', c, 'Accuracy', accuracy)\n",
        "    \n",
        "    max_accurarcy_id = accuracy_score_list.index(max(accuracy_score_list))\n",
        "    return C[max_accurarcy_id] "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caqnWEnCXw0B",
        "outputId": "ab11c15a-eeb9-47a7-c510-bcfd4cf1a302",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "net = input(\"Enter the Net (resnet or eff)\")\n",
        "k = input(\"Enter the K (must be 5 or 10)\")\n",
        "\n",
        "accsSVM = []\n",
        "accsBayes = []\n",
        "model = createModel(net)\n",
        "\n",
        "saveFile = createSaveFile(net)\n",
        "\n",
        "for i in range (1, 11):\n",
        "  \n",
        "  print(\"ROUND \", i)\n",
        "\n",
        "  train_dir, test_dir = loadDir(k, i)\n",
        "\n",
        "  X_list_train, Y_list_train = extract_features_train(train_dir, model)\n",
        "  X_list_test, Y_list_test = extract_features_test(test_dir, model)\n",
        "\n",
        "  train_imgs, train_labels, test_imgs, test_labels = toArray(X_list_train, Y_list_train, X_list_test, Y_list_test)\n",
        "\n",
        "  print(\"train/test images shape\")\n",
        "  print(train_imgs.shape)\n",
        "  print(test_imgs.shape)\n",
        "\n",
        "  reduc_features_train = reduct_features(train_imgs)\n",
        "  reduc_features_test = reduct_features(test_imgs)\n",
        "\n",
        "  ##### DESCOMENTE ISSO PARA RODAR SEM PCA \n",
        "  # reduc_features_train = train_imgs\n",
        "  # reduc_features_test = test_imgs\n",
        "\n",
        "  print(\"reduc train/test images shape\")\n",
        "  print(reduc_features_train.shape)\n",
        "  print(reduc_features_test.shape)\n",
        "\n",
        "  C, kernel = [0.1 * i for i in range(1, 30)], 'linear'\n",
        "  opt_c = svm_grid_search(C, kernel, reduc_features_train, train_labels)\n",
        "\n",
        "  for clfs in classificators:\n",
        "\n",
        "    if clfs == \"svm\":\n",
        "      clf = SVC(C = opt_c, kernel= 'linear')\n",
        "      classificate(clfs, clf, accsSVM, reduc_features_train, train_labels, reduc_features_test, test_labels, saveFile)\n",
        "    if clfs == \"bayes\":\n",
        "      clf = naive_bayes.GaussianNB()\n",
        "      classificate(clfs, clf, accsBayes, reduc_features_train, train_labels, reduc_features_test, test_labels, saveFile)\n",
        "    \n",
        "\n",
        "print(\"Result SVM: \", np.mean(accsSVM))\n",
        "print(\"Result Bayes: \", np.mean(accsBayes))\n",
        "\n",
        "saveFile.write(\"Result SVM: \"+ str(np.mean(accsSVM)))\n",
        "saveFile.write(\"Result Bayes: \"+ str(np.mean(accsBayes)))\n",
        "\n",
        "saveFile.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the Net (resnet or eff)resnet\n",
            "Enter the K (must be 5 or 10)5\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102973440/102967424 [==============================] - 1s 0us/step\n",
            "ROUND  1\n",
            "extracting features\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}