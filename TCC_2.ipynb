{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TCC-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMulqEf4AYKYjyUsLiOAbLY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victoralcantara75/erythrocytes-classification/blob/feature-extraction/TCC_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeBHdOx21G22"
      },
      "source": [
        "#math\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import skimage\n",
        "import sklearn.model_selection\n",
        "\n",
        "#ts and keras\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#dimensionality\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#classificators\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#visualization\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#utils\n",
        "import os\n",
        "import imageio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POrVE1u93Zns",
        "outputId": "08dde151-6d54-4a68-bb17-298cbc93ea6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#dataset\n",
        "!git clone https://github.com/victoralcantara75/train-test-erythrocytes.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'train-test-erythrocytes'...\n",
            "remote: Enumerating objects: 769, done.\u001b[K\n",
            "remote: Counting objects: 100% (769/769), done.\u001b[K\n",
            "remote: Compressing objects: 100% (565/565), done.\u001b[K\n",
            "remote: Total 769 (delta 203), reused 766 (delta 203), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (769/769), 738.18 KiB | 19.95 MiB/s, done.\n",
            "Resolving deltas: 100% (203/203), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCt_jyqMaaCR"
      },
      "source": [
        "classes = [\"circular\", \"falciforme\", \"outras\"]\n",
        "batch = 16\n",
        "epochs = 30\n",
        "opt = 'adam'\n",
        "lr = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36RMZfSnUgR_"
      },
      "source": [
        "def loadDir(round):\n",
        "  train_dir = './train-test-erythrocytes/dataset/5-fold/round_'+str(round)+'/train'\n",
        "  test_dir = './train-test-erythrocytes/dataset/5-fold/round_'+str(round)+'/test'\n",
        "  return train_dir, test_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpdK7l2sZnl3"
      },
      "source": [
        "def loadGenerator(train_dir, test_dir):\n",
        "\n",
        "  train_datagen = ImageDataGenerator(\n",
        "                          rescale=1. / 255,\n",
        "                          shear_range=0.2,\n",
        "                          zoom_range=0.2,\n",
        "                          vertical_flip=True,\n",
        "                          horizontal_flip=True)\n",
        "  test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(train_dir, batch_size = batch)\n",
        "  test_generator = test_datagen.flow_from_directory(test_dir, batch_size = batch)\n",
        "  return train_generator, test_generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJQmLKssYaUW"
      },
      "source": [
        "def createModel():\n",
        "\n",
        "  base_model = ResNet50(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
        "  vector = base_model.get_layer(\"avg_pool\").output\n",
        "  model = tf.keras.Model(base_model.input, vector)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cne2pnAZpSl_"
      },
      "source": [
        "def extract_features_test(path, model):\n",
        "  \n",
        "  x_list = []\n",
        "  y_list = []\n",
        "\n",
        "  for label in range(3):    \n",
        "    folder_path = os.path.join(path, classes[label])\n",
        "    for file in os.listdir(folder_path):    \n",
        "        file_path = os.path.join(folder_path, file)\n",
        "        \n",
        "        if not(file.endswith(\".jpg\")):\n",
        "            continue\n",
        "        \n",
        "        # load image\n",
        "        img = image.load_img(file_path, target_size=(224,224))\n",
        "        # convert image to numpy array\n",
        "        img_arr = image.img_to_array(img)\n",
        "        # add 1 more dimension\n",
        "        img_arr_b = np.expand_dims(img_arr, axis=0)\n",
        "        # preprocess image\n",
        "        input_img = preprocess_input(img_arr_b)\n",
        "        # extract feature\n",
        "        features = model.predict(input_img)\n",
        "\n",
        "        x_list.append(features.ravel())\n",
        "        y_list.append(label)\n",
        "\n",
        "  return x_list, y_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYEYax2fKtYK"
      },
      "source": [
        "def extract_features_train(path, model):\n",
        "  \n",
        "  x_list = []\n",
        "  y_list = []\n",
        "\n",
        "  for label in range(3):    \n",
        "    folder_path = os.path.join(path, classes[label])\n",
        "    for file in os.listdir(folder_path):    \n",
        "        file_path = os.path.join(folder_path, file)\n",
        "        \n",
        "        if not(file.endswith(\".jpg\")):\n",
        "            continue\n",
        "        \n",
        "        # load image\n",
        "        img = image.load_img(file_path, target_size=(224,224))\n",
        "        # convert image to numpy array\n",
        "        img_arr = image.img_to_array(img)\n",
        "        # add 1 more dimension\n",
        "        img_arr_b = np.expand_dims(img_arr, axis=0)\n",
        "        # preprocess image\n",
        "        input_img = preprocess_input(img_arr_b)\n",
        "        #data augmentation\n",
        "        da = []\n",
        "        img_vertical_flip = np.flipud(input_img)\n",
        "        img_horizontal_flip = np.fliplr(input_img)\n",
        "        da.append(input_img)\n",
        "        da.append(img_vertical_flip)\n",
        "        da.append(img_horizontal_flip)\n",
        "        # extract feature\n",
        "        for data in da:\n",
        "          features = model.predict(data)\n",
        "          x_list.append(features.ravel())\n",
        "          y_list.append(label)\n",
        "\n",
        "  return x_list, y_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZmZH53BOe45"
      },
      "source": [
        "def svm_grid_search(C, kernel, train_X, train_Y):\n",
        "    accuracy_score_list = []\n",
        "    \n",
        "    for c in C:\n",
        "        # Model training\n",
        "        svmClassifier = SVC(C = c, kernel = kernel)\n",
        "        svmClassifier.fit(train_X, train_Y.ravel())\n",
        "        # Prediction on test set\n",
        "        pred_y = svmClassifier.predict(train_X)\n",
        "        # Accuracy\n",
        "        accuracy = accuracy_score(train_Y, pred_y)\n",
        "        accuracy_score_list.append(accuracy)\n",
        "        print('Regularization parameters: ', c, 'Accuracy', accuracy)\n",
        "    \n",
        "    max_accurarcy_id = accuracy_score_list.index(max(accuracy_score_list))\n",
        "    return C[max_accurarcy_id] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caqnWEnCXw0B",
        "outputId": "951d4df5-03ce-4357-a8bb-028ad5431013",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "accs = []\n",
        "\n",
        "for i in range (1, 2):\n",
        "  \n",
        "  print(\"ROUND \", i)\n",
        "  train_dir, test_dir = loadDir(i)\n",
        "\n",
        "  model = createModel()\n",
        "\n",
        "  X_list_train, Y_list_train = extract_features_train(train_dir, model)\n",
        "  X_list_test, Y_list_test = extract_features_test(test_dir, model)\n",
        "\n",
        "  train_imgs = np.asarray(X_list_train, dtype=np.float32)\n",
        "  train_labels = np.asarray(Y_list_train, dtype=np.float32)\n",
        "\n",
        "  test_imgs = np.asarray(X_list_test, dtype=np.float32)\n",
        "  test_labels = np.asarray(Y_list_test, dtype=np.float32)\n",
        "\n",
        "  print(\"Shape of train_X\")\n",
        "  print(train_imgs.shape)\n",
        "  print(\"\\nShape of test_X\")\n",
        "  print(test_imgs.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROUND  1\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102973440/102967424 [==============================] - 1s 0us/step\n",
            "Shape of train_X\n",
            "(1500, 2048)\n",
            "\n",
            "Shape of test_X\n",
            "(126, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxINm3g9S4YH",
        "outputId": "4f5a67ee-e42a-4d25-b5ab-69b8eee03897",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "  pca = PCA()\n",
        "  pca.fit(train_imgs)\n",
        "  reduc_features_train = pca.transform(train_imgs)\n",
        "\n",
        "  pca.fit(test_imgs)\n",
        "  reduc_features_test = pca.transform(test_imgs)\n",
        "\n",
        "  print(reduc_features_train.shape)\n",
        "  print(reduc_features_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1500, 126)\n",
            "(126, 126)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9kAwnTVQ1aZ",
        "outputId": "2c7466b4-6088-40e7-997c-b31f1a00c9a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "C, kernel = [0.1 * i for i in range(1, 30)], 'linear'\n",
        "opt_c = svm_grid_search(C, kernel, reduc_features_train, train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regularization parameters:  0.1 Accuracy 0.5226666666666666\n",
            "Regularization parameters:  0.2 Accuracy 0.6093333333333333\n",
            "Regularization parameters:  0.30000000000000004 Accuracy 0.6246666666666667\n",
            "Regularization parameters:  0.4 Accuracy 0.6426666666666667\n",
            "Regularization parameters:  0.5 Accuracy 0.6573333333333333\n",
            "Regularization parameters:  0.6000000000000001 Accuracy 0.674\n",
            "Regularization parameters:  0.7000000000000001 Accuracy 0.692\n",
            "Regularization parameters:  0.8 Accuracy 0.6933333333333334\n",
            "Regularization parameters:  0.9 Accuracy 0.706\n",
            "Regularization parameters:  1.0 Accuracy 0.7126666666666667\n",
            "Regularization parameters:  1.1 Accuracy 0.718\n",
            "Regularization parameters:  1.2000000000000002 Accuracy 0.7233333333333334\n",
            "Regularization parameters:  1.3 Accuracy 0.7306666666666667\n",
            "Regularization parameters:  1.4000000000000001 Accuracy 0.734\n",
            "Regularization parameters:  1.5 Accuracy 0.738\n",
            "Regularization parameters:  1.6 Accuracy 0.7426666666666667\n",
            "Regularization parameters:  1.7000000000000002 Accuracy 0.7426666666666667\n",
            "Regularization parameters:  1.8 Accuracy 0.746\n",
            "Regularization parameters:  1.9000000000000001 Accuracy 0.7473333333333333\n",
            "Regularization parameters:  2.0 Accuracy 0.75\n",
            "Regularization parameters:  2.1 Accuracy 0.7526666666666667\n",
            "Regularization parameters:  2.2 Accuracy 0.758\n",
            "Regularization parameters:  2.3000000000000003 Accuracy 0.7593333333333333\n",
            "Regularization parameters:  2.4000000000000004 Accuracy 0.7613333333333333\n",
            "Regularization parameters:  2.5 Accuracy 0.7606666666666667\n",
            "Regularization parameters:  2.6 Accuracy 0.76\n",
            "Regularization parameters:  2.7 Accuracy 0.7646666666666667\n",
            "Regularization parameters:  2.8000000000000003 Accuracy 0.766\n",
            "Regularization parameters:  2.9000000000000004 Accuracy 0.7693333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXTb6ohB35Im",
        "outputId": "f64e3f5f-ca15-4037-d2ab-906891443d92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "  clf = SVC(C= opt_c, kernel= 'linear')\n",
        "  clf.fit(train_imgs, train_labels)\n",
        "  preds = clf.predict(test_imgs)\n",
        "  print(classification_report(test_labels, preds, target_names=classes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    circular       0.71      0.66      0.68        41\n",
            "  falciforme       0.93      0.64      0.76        42\n",
            "      outras       0.58      0.79      0.67        43\n",
            "\n",
            "    accuracy                           0.70       126\n",
            "   macro avg       0.74      0.70      0.70       126\n",
            "weighted avg       0.74      0.70      0.70       126\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}